{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue> *Stats507  , WI 2019*</font>\n",
    "### Zizhao Zhang\n",
    "#### zizhaoz@umich.edu\n",
    "***\n",
    "\n",
    "Time spent on problems(hours):   *Problem 1*: 15 minutes , *Problem 2*: 4 hour *Problem 3*: 2 hour\n",
    "\n",
    "Persons discussed idea about: Hongru Fang，Thomas Fiore\n",
    "\n",
    "***\n",
    "**REQUIRE MODULE:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Warmup: Constructing a 3-tensor (1 point):\n",
    "Create a TensorFlow constant tensor **tflogo** with shape 5-by-4-by-3. This tensor will\n",
    "represent the 5-by-4-by-3 volume that contains the orange structure depicted in the logo\n",
    "(said another way, the orange structure is inscribed in this 5-by-4-by-3 volume). \n",
    "***\n",
    "Each cell of your tensor should correspond to one cell in this volume. Each entry of your tensor\n",
    "should be 1 if and only if the corresponding cell is part of the orange structure, and should\n",
    "be 0 otherwise.\n",
    "***\n",
    "Looking at the logo, we see that the orange structure can be broken into\n",
    "11 cubic cells, so your tensor **tflogo** should have precisely 11 non-zero entries. For the\n",
    "sake of consistency, the (0, 3, 2)-entry of your tensor (using 0-indexing) should correspond\n",
    "to the top rear corner of the structure where the cross of the “T” meets the top of the\n",
    "“F”. Note: if you look carefully, the shadows in the logo do not correctly reflect the\n",
    "orange structure—the shadow of the “T” is incorrectly drawn. Do not let this fool you!\n",
    "***\n",
    "To clarify: I drew the below illustration\n",
    "<a href=\"http://tinypic.com?ref=2lb3es\" target=\"_blank\"><img src=\"http://i67.tinypic.com/2lb3es.jpg\" border=\"0\" alt=\"Image and video hosting by TinyPic\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###make sure version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since tf.zeros doesn't support indexing assignment for the \"ones\", which are the orange blocks, I chose to use numpy to create the basic structure first for the ease, and then convert back to a tensor\n",
    "\n",
    "create the tensor in five layers, starting from the \"rear corner\" labeled in the above image\n",
    "at the index 0- from top to down. <font color = red>In that first layer should be a \"L\" shape, 2nd, 4th, 5th layer should be a one dot at (2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create 5 layers from top to down\n",
    "layer1 = np.zeros([4,3])\n",
    "#same reference\n",
    "layer2 = layer4 = layer5 = np.zeros([4,3])\n",
    "#layer4\n",
    "layer3 = np.zeros([4,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1[3,2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(layer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fill the layer1 to L shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the 3rd column and 4th row to all ones\n",
    "layer1[:,2] = 1\n",
    "layer1[3,:] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd, 4th, 5th layer should be a one dot at (2,2), **note we only need to reference one of them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2[2,2] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assign layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer3[2,2] = 1\n",
    "layer3[2,1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack them into a 5 * 4 * 3 dimension numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 1.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 1. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "tensor = np.stack((layer1, layer2, layer3, layer4, layer5))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the nparray looks right, make it a tensor now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflogo = tf.constant(tensor, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 1.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 1. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print_sess = tf.Session()\n",
    "#print the tensor to check it\n",
    "print(tflogo.eval(session = print_sess))\n",
    "print_sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probelm 2: Building and training simple models (4 points):\n",
    "In all cases, your answer should include placeholder variables x and ytrue , which will serve as the predictor (independent variable) and response (dependent variable), respectively. Please use **W** to denote a parameter that multiplies the\n",
    "predictor, and b to denote a bias parameter (i.e., a parameter that is added)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1: Logistic regression with a negative log-likelihood loss.\n",
    "\n",
    "In this model, which\n",
    "we discussed briefly in class, the binary variable Y is distributed as a Bernoulli\n",
    "random variable with success parameter $$ \\text {}\n",
    "\\sigma\\left(W^{T} X+b\\right), \\text { where } \\sigma(z)=(1+\\exp (-z))^{-1}\n",
    "\\text {is the logistic function, and } \n",
    "X \\in \\mathbb{R}^{6} \\text {is the predictor random variable, and } W \\in \\mathbb{R}^{6}, \n",
    "b \\in \\mathbb{R} \\text { are the model parameters. Derive the log-likelihood of } Y \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "###we sure about the two place_holders\n",
    "x = tf.placeholder(tf.float32, [None,6])\n",
    "#set the dimension to 2 since binary\n",
    "ytrue = tf.placeholder(tf.float32, [None, 1])#response\n",
    "##and W is a dimensinoal vars used for mult\n",
    "W = tf.Variable(tf.ones([6,1]), dtype = tf.float32)\n",
    "#bias \n",
    "b = tf.Variable(tf.zeros(1), dtype = tf.float32)\n",
    "#define z = w^t*x+b\n",
    "z = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text {Note: }z = W^{T} X+b, \n",
    "\\operatorname{Pr}(Y=1 |  X,w) = \\sigma\\left(W^{T} X+b\\right),\n",
    "and  \n",
    " \\operatorname{Pr}(Y=0 |  X,w) = 1-\\sigma\\left(W^{T} X+b\\right) = \\sigma(-z)=(1+\\exp (z))^{-1}\n",
    " , \\text{then we have the negative loss } =\n",
    " -1/m*(\\sum_{i=1}^{m}\\left[y^{(i)} \\log \\left(h_{\\theta}\\left(x^{(i)}\\right)\\right)+\\left(1-y^{(i)}\\right) \\log \\left(1-h_{\\theta}\\left(x^{(i)}\\right)\\right)\\right])\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then define probability of the bernoulli as h\n",
    "h = 1.0/(1.0 + tf.exp(-z))\n",
    "#define negative log-likelihood loss/cross entropy\n",
    "loss = -1.0*tf.reduce_mean((ytrue * tf.log(h)) + (1-ytrue)*tf.log(1-h))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###test it out#####optional\n",
    "init_sample = tf.global_variables_initializer()\n",
    "example1 = tf.Session()\n",
    "example1.run(init_sample)\n",
    "example1.run(loss, {x: np.random.rand(100,6),\n",
    "                    ytrue: np.random.randint(2, size=[100,1])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### 2.2 Estimating parameters in logistic regression.\n",
    "\n",
    "    • logistic_xtest.npy : contains a 500-by-6 matrix \n",
    "    • logistic_xtrain.npy : contains a 2000-by-6 matrix \n",
    "    • logistic_ytest.npy : contains a binary 500-dimensional vector \n",
    "    • logistic_ytrain.npy : contains a binary 2000-dimensional vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the npy files\n",
    "xtrain = np.load(\"./logistic_xtrain.npy\")\n",
    "xtest = np.load(\"./logistic_xtest.npy\")\n",
    "ytrain = np.load(\"./logistic_ytrain.npy\")\n",
    "ytest = np.load(\"./logistic_ytest.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data and use it to obtain estimates of W and b by minimizing\n",
    "the negative log-likelihood via gradient descent. Another note: you’ll have to play\n",
    "around with the learning rate and the number of steps. Two good ways to check if\n",
    "optimization is finding a good minimizer:\n",
    "    \n",
    "    • Try printing the training data loss before and after optimization.\n",
    "\n",
    "    • Use the test data to validate your estimated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 6), (2000, 1))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check shapes\n",
    "xtrain.shape, ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the variables and assign their default value\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated W is [[0.95293915]\n",
      " [1.2035762 ]\n",
      " [1.4516773 ]\n",
      " [2.9309719 ]\n",
      " [4.5173965 ]\n",
      " [7.3281064 ]] and b is -0.93471\n",
      "Mean of the loss of 10000 iterations renders as 0.35209\n"
     ]
    }
   ],
   "source": [
    "#set up gradient descent optimizer with learning rate\n",
    "train_optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(loss)\n",
    "\n",
    "num_iters = 10000\n",
    "#list for plotting and storing cost\n",
    "cost = np.zeros(num_iters)\n",
    "#accuracy_list = np.zeros(num_iters)\n",
    "#sess.run(init)\n",
    "for i in range(num_iters):\n",
    "    #store the cost/loss\n",
    "    cost[i] = sess.run(loss, {x: xtrain,\n",
    "                                    ytrue: ytrain})\n",
    "    sess.run(train_optimizer, {x:xtrain, ytrue:ytrain})\n",
    "print(\"The estimated W is %s and b is %.5f\"% (sess.run([W,b])[0],sess.run([W,b])[1]))\n",
    "print(\"Mean of the loss of %d iterations renders as %.5f\"%(num_iters, np.mean(cost)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the iteration and the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost)\n",
    "#plt.axis([0,num_iters,0,np.max(cost)])\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"cost\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3: Evaluating logistic regression on test data.\n",
    "Load the test data. What is the\n",
    "negative log-likelihood of your model on this test data? That is, what is the negative\n",
    "log-likelihood when you use your estimated parameters with the previously unseen\n",
    "test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 6), (500, 1))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###test datas are already loaded\n",
    "#check shapes\n",
    "xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is also calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated W is [[0.95293915]\n",
      " [1.2035762 ]\n",
      " [1.4516773 ]\n",
      " [2.9309719 ]\n",
      " [4.5173965 ]\n",
      " [7.3281064 ]] and b is -0.93471\n",
      "Negative likelihood on the test set is  0.32706\n",
      "The test accuracy is 0.858000\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5\n",
    "correct_prediction = tf.cast(tf.greater(h, threshold), tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.to_float(tf.equal(ytrue, correct_prediction)))\n",
    "print(\"The estimated W is %s and b is %.5f\"% (W.eval(session = sess),sess.run(b)))\n",
    "print(\"Negative likelihood on the test set is  %.5f\"% sess.run(loss, {x:xtest, ytrue: ytest}))\n",
    "#optional\n",
    "print(\"The test accuracy is %f\"% sess.run(accuracy, {x:xtest, ytrue: ytest}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4: Evaluating the estimated logistic parameters.\n",
    "The data was, in reality, generated with:\n",
    "\n",
    "$$W=(1,1,2,3,5,8), \\quad b=-1$$\n",
    "Write TensorFlow expressions to compute the squared error between your estimated\n",
    "parameters and their true values. Evaluate the error in recovering W and b separately. What are the squared errors? **Note:** you need only evaluate the error of\n",
    "your final estimates, not at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "###contruct new Ws and b \n",
    "#make sure W is 6*1\n",
    "W_true = tf.constant(np.array([[1], [1], [2], [3], [5], [8]]), dtype=tf.float32)\n",
    "b_true = tf.constant(-1,  dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared error of W is 1.033428 and Squared error of b is 0.004262\n"
     ]
    }
   ],
   "source": [
    "#init_true = tf.variables_initializer((W_true,b_true)).run(session = sess)\n",
    "#run session\n",
    "#sess.run(init_true)\n",
    "#cannot initialize globally or else W value changes\n",
    "#tf.global_variables_initializer().run(session = sess)\n",
    "'''calculate square_error'''\n",
    "Wsqerr = tf.reduce_sum(tf.square(sess.run([W,b])[0] - W_true))\n",
    "bsqerr = tf.reduce_sum(tf.square(sess.run([W,b])[1] - b_true))\n",
    "print(\"Squared error of W is %f and Squared error of b is %f\" % \\\n",
    "      (Wsqerr.eval(session = sess), bsqerr.eval(session = sess)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5: \n",
    "For ease of grading, please make the variables from the above problems available\n",
    "in a dictionary called **results_logistic**. The dictionary should have keys **’W’**,\n",
    "**’Wsqerr’**, **’b’**, **’bsqerr’**, **’log_lik_test’** , with respective values sess.run(x)\n",
    "where x ranges over the corresponding quantities. For example, if my squared error\n",
    "for W is stored in a TF variable called W_squared_error, then the key ’Wsqerr’\n",
    "should have value sess.run(W_squared_error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_logistic = {\"W\": sess.run(W),\n",
    "                    \"Wsqerr\": sess.run(Wsqerr),\n",
    "                    \"b\": sess.run(b),\n",
    "                    \"bsqerr\": sess.run(bsqerr),\n",
    "                    \"log_lik_test\": sess.run(loss, {x:xtest, ytrue: ytest})}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W': array([[0.95293915],\n",
      "       [1.2035762 ],\n",
      "       [1.4516773 ],\n",
      "       [2.9309719 ],\n",
      "       [4.5173965 ],\n",
      "       [7.3281064 ]], dtype=float32), 'Wsqerr': 1.0334278, 'b': array([-0.9347123], dtype=float32), 'bsqerr': 0.004262485, 'log_lik_test': 0.327055}\n"
     ]
    }
   ],
   "source": [
    "print(results_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6: Classification of normally distributed data. \n",
    "\\begin{array}{l}{K=3 \\text { different classes. Each class } k \\in\\{1,2,3\\} \\text { has an associated mean } \\mu_{k} \\in R \\text { and }} \\\\ {\\text { variance } \\sigma_{k}^{2} \\in \\mathbb{R}, \\text { and all observations from a given class are i.i.d. } \\mathcal{N}\\left(\\mu_{k}, \\sigma_{k}^{2}\\right) . \\text { The }} \\\\ {\\text { four files are: }}\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "normal_xtest = np.load(\"./normal_xtest.npy\")\n",
    "normal_xtrain = np.load(\"./normal_xtrain.npy\")\n",
    "#labels\n",
    "normal_ytrain = np.load(\"./normal_ytrain.npy\")\n",
    "normal_ytest = np.load(\"./normal_ytest.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 1), (2000, 1), (2000, 3), (500, 3))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify shapes\n",
    "normal_xtest.shape, normal_xtrain.shape, normal_ytrain.shape, normal_ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "####set ups\n",
    "K = 3\n",
    "mu = tf.Variable(tf.ones([1,K]), dtype = tf.float32)\n",
    "#note this is var-sigma squared\n",
    "sigma_2 = tf.Variable(tf.ones([1,K]), dtype = tf.float32)\n",
    "##ytrue and x\n",
    "x = tf.placeholder(tf.float32, [None, 1])\n",
    "ytrue = tf.placeholder( tf.float32, [None, 3])\n",
    "#normal distribution\n",
    "normal_dis =  tfp.distributions.Normal(loc=mu, scale=tf.sqrt(sigma_2)).prob(x)\n",
    "#define cross-entropy\n",
    "cross_entropy = -1.0 * tf.reduce_mean(tf.reduce_sum(ytrue * tf.log(normal_dis)))\n",
    "# Optimize via stochastic gradient descent\n",
    "train_step = tf.train.AdagradOptimizer(0.05).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By training, means're predicated as [-1.0076301   0.00449134  3.004821  ] \n",
      " and the variances're predicated as [0.53338194 1.0087556  1.515918  ] \n"
     ]
    }
   ],
   "source": [
    "###take 10000 steps as always,\n",
    "num_iters = 10000\n",
    "# Start up a session.\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "#sess.run(init)\n",
    "cost = np.zeros(num_iters)\n",
    "for i in range(num_iters):\n",
    "    sess.run(train_step, feed_dict={x: normal_xtrain, ytrue: normal_ytrain})\n",
    "    cost[i] = sess.run(cross_entropy, {x: normal_xtest, ytrue: normal_ytest})\n",
    "print(\"By training, means're predicated as %s \\n and the variances're predicated as %s \"%\n",
    "      (sess.run([mu, sigma_2])[0][0],sess.run([mu, sigma_2])[1][0] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7: Evaluating loss on test data\n",
    "Load the test data. What is the cross-entropy of\n",
    "your model on this test data? That is, what is the cross-entropy when you use your\n",
    "estimated parameters with the previously unseen test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost)\n",
    "#plt.axis([0,num_iters,0,np.max(cost)])\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"cross_entropy\")\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-entropy is 686.346802 \n"
     ]
    }
   ],
   "source": [
    "print(\"cross-entropy is %f \"%sess.run(cross_entropy, {x: normal_xtest, ytrue: normal_ytest}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8: Evaluating parameter estimation on test data.\n",
    "The true parameter values for the three classes were $$\n",
    "\\begin{aligned} \\mu_{0} &=-1, \\sigma_{0}^{2}=0.5 \\\\ \\mu_{1} &=0, \\sigma_{1}^{2}=1 \\\\ \\mu_{2} &=3, \\sigma_{2}^{2}=1.5 \\end{aligned}\n",
    "$$\n",
    "Write a TensorFlow expression to compute the total squared error (i.e., summed\n",
    "over the six parameters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squared error is 0.001546 \n"
     ]
    }
   ],
   "source": [
    "mu_true = tf.constant([[-1, 0, 3]], dtype = tf.float32)\n",
    "sigma_true = tf.constant([[0.5, 1, 1.5]], dtype = tf.float32)\n",
    "#squared error\n",
    "class_error = tf.reduce_sum(tf.square(mu - mu_true)) + \\\n",
    "              tf.reduce_sum(tf.square(sigma_2 - sigma_true))\n",
    "print(\"Squared error is %f \"%sess.run(class_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9: Evaluating classification error on test data. \n",
    "Write and evaluate a TensorFlow\n",
    "expression that computes the classification error of your estimated model averaged\n",
    "over the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate is 0.268000 \n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(normal_dis, 1), tf.argmax(ytrue, 1))\n",
    "error_rate = 1 - tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"error rate is %f \"%sess.run(error_rate, {x:normal_xtest, ytrue: normal_ytest}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.10: \n",
    " Again, for ease of grading, define a dictionary called results_class, with keys\n",
    "’mu’, ’sigma2’, ’crossent_test’, ’class_error’ with keys corresponding to\n",
    "the evaluation (again using sess.run) of your estimate of $$\\mu, \\sigma^2$$\n",
    ", the cross-entropy\n",
    "on the test set, and the classification error from the previous problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mu': array([-1.0076301 ,  0.00449134,  3.004821  ], dtype=float32), 'sigma2': array([0.53338194, 1.0087556 , 1.515918  ], dtype=float32), 'crossent_test': 686.3468, 'class_error': 0.268}\n"
     ]
    }
   ],
   "source": [
    "results_class = {\"mu\" : sess.run([mu, sigma_2])[0][0],\n",
    "                 \"sigma2\" : sess.run([mu, sigma_2])[1][0],\n",
    "                 \"crossent_test\" : sess.run(cross_entropy, {x: normal_xtest,\n",
    "                                                             ytrue: normal_ytest}),\n",
    "                 \"class_error\" : sess.run(error_rate, {x:normal_xtest, ytrue: normal_ytest})}\n",
    "print(results_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Building a Complicated Model (1 point)\n",
    "I chose to follow along: https://www.tensorflow.org/tutorials/estimators/boosted_trees\n",
    "under the ML at production scale\n",
    "***\n",
    "Details please follow tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 4: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 :\n",
    "follow the mnist page:https://cloud.google.com/ml-engine/docs/tensorflow/distributed-tensorflow-mnist-cloud-datalab\n",
    "\n",
    "result is shown as below as the prediction is based on the figure drawn\n",
    "<a href=\"http://tinypic.com?ref=3449x15\" target=\"_blank\"><img src=\"http://i68.tinypic.com/3449x15.png\" border=\"0\" alt=\"Image and video hosting by TinyPic\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2:\n",
    "Let us return to the classifier that you trained above on the normally-distributed\n",
    "data. In this and the next several subproblems, we will take an adaptation of that\n",
    "model and upload it to GCP where it will serve as a prediction node similar to the one\n",
    "you built in the tutorial above. Train the same classifier on the same training data,\n",
    "but this time, save the resulting trained model in a directory called normal_trained.\n",
    "You’ll want to use the tf.saved_model.simple_save function. Refer to the GCP documentation at\n",
    "https://cloud.google.com/ml-engine/docs/deploying-models,\n",
    "and the documentation on the tf.saved_model.simple_save function, here: https:\n",
    "//www.tensorflow.org/programmers_guide/saved_model#save_and_restore_models\n",
    "Please include a copy of this model directory in your submission. Hint: a stumbling\n",
    "block in this problem is figuring out what to supply as the inputs and outputs arguments to the simple_save function. Your arguments should look something like\n",
    "inputs = {’x’:x}, outputs = {’prediction’:prediction}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"normal_trained\"):\n",
    "    tf.saved_model.simple_save(sess, \"normal_trained\", inputs = {\"x\":x}, \n",
    "                           outputs = {\"prediction\": normal_dis})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4:\n",
    "\n",
    "Model version created as below \n",
    "<a href=\"http://tinypic.com?ref=258wdjd\" target=\"_blank\"><img src=\"http://i67.tinypic.com/258wdjd.png\" border=\"0\" alt=\"Image and video hosting by TinyPic\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5: \n",
    "commands and screenshots are listed below"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vim instance.hw10.json\n",
    "\n",
    "{“x”:4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6:\n",
    "commands and screenshots of shell:\n",
    "<a href=\"http://tinypic.com?ref=264osye\" target=\"_blank\"><img src=\"http://i65.tinypic.com/264osye.png\" border=\"0\" alt=\"Image and video hosting by TinyPic\"></a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MODEL_NAME=stats507w19_hw10_normal\n",
    "INPUT_DATA_FILE=\"instance.hw10.json\"\n",
    "VERSION_NAME=stats507w19_hw10_normal\n",
    "\n",
    "\n",
    "gcloud ml-engine predict --model $MODEL_NAME  \\\n",
    "                   --version $VERSION_NAME \\\n",
    "                   --json-instances instance.hw10.json\n",
    "\n",
    "gcloud ml-engine predict --model $MODEL_NAME  \\\n",
    "                   --version $VERSION_NAME \\\n",
    "                   --json-instances $INPUT_DATA_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### note the class is from the third class, which is class 2 due to zero based index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
